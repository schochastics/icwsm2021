---
-
    UID: a
    title: "Hate speech: Detection, Mitigation and Beyond"
    authors: "Punyajoy Saha|Binny Mathew|Mithun Das|Pawan Goyal|Kiran Garimella|Animesh Mukherjee"
    link: https://hate-alert.github.io/talk/icwsm_tutorial/
    logo: https://i.imgur.com/DaALwIq.png
    abstract: "Social media sites such as Twitter and Facebook have connected billions of people and given the opportunity to the users to share their ideas and opinions instantly. That being said, there are several ill consequences as well such as online harassment, trolling, cyber-bullying, fake news, and hate speech. Out of these, hate speech presents a unique challenge as it is deep engraved into our society and is often linked with offline violence. Social media platforms rely on local moderators to identify hate speech and take necessary action, but with a prolific increase in such content over social media many are turning toward automated hate speech detection and mitigation systems. This shift brings several challenges on the plate, and hence, is an important avenue to explore for the computation social science community. In this translation style tutorial, we present an exposition of hate speech detection and mitigation in three steps. First, we shall describe the current state of research in the hate speech domain, focusing on different detection and mitigation systems that have developed over time. Next, we shall highlight the challenges that these systems might carry like bias and lack of transparency. The final section will concretize the path ahead, providing clear guidelines for the community working on hate speech and related areas. We shall outline the open challenges and research directions for interested researchers. Here, we plan to cover the following topics, i) How is hate speech affecting different platforms? ii) Existing dataset, iii) Text-based hate speech systems, iv) User-based hate speech systems, v) How we can mitigate or slow down the process of spread of hate speech, vi) What are the challenges still present in the domain, e.g.: Explainability and bias, Multimodal and multilingual challenges etc, in the tutorial."
-
    UID: b
    title: "Engaging the Ethics of “Public” Data in Social Media Research"
    authors: "Casey Fiesler|Katharina Kinder-Kurlanda|Jacob Metcalf|Emmanuel
    Moss|Katie Shilton|Michael Zimmer"
    link: https://icwsm.org/2021/index.html#tutorials_schedule
    logo: https://via.placeholder.com/254x55/FFFFFF/FFFFFF%20?Text=a
    abstract: "This tutorial bridges social media research methods with concepts in ethics and privacy. Researchers studying the web and social media find themselves immersed in a domain where data flows freely and is often considered “public,” but that data is also potentially bound by contextual norms and expectations. While many research communities have engaged with the ethics of data collection, sharing, and retention practices, these debates are often less-visible to parts of the data and computational social science communities. In this tutorial, we will engage the concept of contextual integrity to provide space for the community to discuss how ethical risks emerge when engaging with “public” data, and offer practical methods for addressing this risk. This tutorial will bridge ongoing conversations in research ethics about practices of data collection and retention with emerging practices of data and computational social science researchers. Participants will gain practical methods for identifying, tracking, and mitigating ethical harms related to the collection and use of “public” data in web and social media research."
-
    UID: c
    title: "Knowledge In - Wisdom Out - Explainable Data for AI in Cyber Social Threats and Public Health"
    authors: "Amit Sheth|Kaushik Roy|Manas Gaur|Usha Lokala"
    link: https://aiisc.ai/kiwo-icwsm/ 
    logo: https://i.imgur.com/aasSlSh.png
    abstract: "In today's data-driven world, organizations derive insights from massive amounts of data through large scale statistical machine learning models. However, statistical techniques can be easy to fool with adversarial instances (a neural network can predict a non-extremist as an extremist by mere presence of the word Jihad), which raises question in Data Quality. In high stakes decision making problems, such as cyber social threats, it is highly sensitive to classify a non-extremist as an extremist and vice-versa. Data quality is good if the data possesses adequate domain coverage and the labels contain adequate semantics. For example, is the semantics of an extremist vs. non-extremist vis-a-vis the word Jihad captured in the label (adequate semantics in labels)? Also, are there enough non-extremists with the word Jihad in the training data from the perspective of religion, hate, or ideology? Thus semantic annotation of the data, beyond mere labels attached to data instances, can significantly improve the robustness of model outcomes and ensure that the model has learned from trustworthy, knowledge-guided data standards. It is important to note that the knowledge-guided standards help de-bias the data if specified correctly (contextualized de-biasing extremist behavior data from bias towards the word Jihad). Therefore, in addition to trust in the robustness of outcomes, knowledge guided data creation also enables fair and ethical practices during real-world deployment of machine learning in high stakes decision making. We denote such data as Explainable Data. In this tutorial of type course and case-studies, we detail how to construct Explainable Data using various expert resources and knowledge graphs. All the materials (resources and implementations) presented during the tutorial will be made available on: KIWO-ICWSM, a week before the tutorial. We plan a 90 minute tutorial (Intermediate Level) with 2 breaks (5 mins each)."
